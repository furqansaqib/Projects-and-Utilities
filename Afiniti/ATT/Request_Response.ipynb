{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c34385e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import csv\n",
    "import urllib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import psycopg2\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "from datetime import datetime, timedelta\n",
    "from sqlalchemy import create_engine\n",
    "from email.mime.text import MIMEText\n",
    "from email.mime.application import MIMEApplication\n",
    "from email.mime.multipart import MIMEMultipart\n",
    "from smtplib import SMTP\n",
    "import smtplib\n",
    "import sys\n",
    "import email\n",
    "from email import encoders\n",
    "from email.mime.base import MIMEBase\n",
    "import json\n",
    "import urllib.parse\n",
    "\n",
    "def Read_Contexts():\n",
    "    myvars = {}\n",
    "    with open(\"/DE/Decisioning_DE/context_DT\") as myfile:\n",
    "        for line in myfile:\n",
    "            name, var = line.partition(\";~\")[::2]\n",
    "            if len(var)>0:\n",
    "                myvars[name.strip()] = var.rstrip(var[-1])\n",
    "            else:\n",
    "                myvars[name.strip()] = var\n",
    "    return myvars\n",
    "\n",
    "\n",
    "def Get_Dates_and_WSA_Data(conn, param_st_dt,param_end_dt):\n",
    "    print(1)\n",
    "# =============================================================================\n",
    "#     stmt = \"\"\"\n",
    "#     SELECT COALESCE(MAX(log_time),'2022-10-01'::date) as max_date\n",
    "#     FROM decisioning_de.processed_responses_v2\n",
    "#     \"\"\"\n",
    "# =============================================================================\n",
    "    if param_st_dt =='' or param_end_dt=='':\n",
    "\n",
    "# =============================================================================\n",
    "#         cursor = conn.cursor()\n",
    "#         cursor.execute(stmt)\n",
    "#         StartDate = cursor.fetchone()[0]\n",
    "#         cursor.close()\n",
    "#         StartDate=StartDate.date()\n",
    "# =============================================================================\n",
    "        StartDate= datetime.now().date() \n",
    "        TodayDate = datetime.now().date() + timedelta(days=1)\n",
    "    else:\n",
    "        StartDate = param_st_dt\n",
    "        TodayDate = param_end_dt\n",
    "    \n",
    " #   yesterday_date = (TodayDate - timedelta(days=1))\n",
    " #  if StartDate != yesterday_date:\n",
    " #       print(\"Data is Updated\")\n",
    " #   else:\n",
    "    print(\"StartDate: \" + str(StartDate) +\"\\n\" + \"EndDate: \" + str(TodayDate))\n",
    "    stmt_read_webService_api = f\"\"\"\n",
    "    select log_time, log_message->'details'->>'client' client,log_message->'details'->>'req_json' client_request, \n",
    "    log_message->'details'->>'response' response \n",
    "    from decisioning_app.web_service_api wsa \n",
    "    where wsa.log_message->'details'->>'path'='/public/get_decision' \n",
    "    AND log_time >= '{str(StartDate)}' and log_time < '{str(TodayDate)}'\n",
    "    \"\"\"\n",
    "    df=pd.read_sql_query(stmt_read_webService_api, conn)\n",
    "    return df,StartDate,TodayDate\n",
    "    \n",
    "def Dodgy_Responses(df_wsa,engine,  conn,  StartDate, TodayDate ):\n",
    "    df_dodgy_stg= df_wsa.query(\"response=='' | response=='{}'\")\n",
    "    df_dodgy_stg['log_time'] = df_dodgy_stg['log_time'].apply(pd.to_datetime)\n",
    "    df_dodgy = df_dodgy_stg.groupby(df_dodgy_stg['log_time'].dt.date).size().reset_index(name='Count')\n",
    "    df_dodgy.rename(columns={'log_time': \"log_date\", \"Count\": \"dodgy_count\"}, inplace=True)\n",
    "    cursor=conn.cursor()\n",
    "    try:\n",
    "        cursor.execute(f\"delete FROM decisioning_de.dodgy_responses WHERE log_date >= '{str(StartDate)}' and log_date < '{str(TodayDate)}'\")\n",
    "        cursor.close()\n",
    "        conn.commit()\n",
    "        print(\"inserting data\")\n",
    "        df_dodgy.to_sql('dodgy_responses', con = engine, schema='decisioning_de', if_exists = 'append', chunksize = 1000, index = False)\n",
    "    except (Exception, psycopg2.DatabaseError) as error:\n",
    "            print(error)\n",
    "def parse_request_response(df_wsa,df_stg):\n",
    "    for index,row in df_wsa.iterrows():\n",
    "        log_time = df_wsa['log_time'][index]\n",
    "        request_string = df_wsa['client_request'].iloc[index]\n",
    "        json_request = json.loads(request_string)\n",
    "        response_string = df_wsa['response'].iloc[index]\n",
    "        json_response = json.loads(response_string)\n",
    "        intent=\"\"\n",
    "        offergroups_req=\"\"\n",
    "        offer_type=\"\"\n",
    "        mban=\"\"\n",
    "        afiniti_rank=0\n",
    "        original_rank=0\n",
    "        rank_change=0\n",
    "        sub_offer_string=\"\"\n",
    "        offergroups_res=\"\"\n",
    "        shuffle =0\n",
    "        n_propositions=0\n",
    "\n",
    "        if response_string!='{}' and response_string!='': #and json_request.get('offerRecord') is not None and json_response.get('offerRecord') is not None:\n",
    "            for offerRecord_req,offerRecord_res in zip(json_request['offerRecord'], json_response['offerRecord']): \n",
    "                n_propositions=0\n",
    "                tdata_id = json_request['transactionId']\n",
    "                mban = json_response['mBan']\n",
    "                sub_offer_list=[]\n",
    "                sub_offer_string=\"\"\n",
    "                if offerRecord_req.get('dispositionLevel') is not None and offerRecord_req.get('inventorySpaceId') is not None:\n",
    "\n",
    "                    if offerRecord_req['dispositionLevel']=='Group' and offerRecord_req['inventorySpaceId'].find('Reactive')!=-1:\n",
    "                        if int(offerRecord_res['Rank'])-int(offerRecord_req['Rank'])!=0:\n",
    "                            shuffle =1\n",
    "                        else:\n",
    "                            shuffle =0\n",
    "                        for subOffer in offerRecord_req['offerGroupMembers']:\n",
    "                            sub_offer_list.append(subOffer['offerGroupMember'])\n",
    "                        sub_offer_list.sort()\n",
    "                        sub_offer_string = '|'.join(sub_offer_list)\n",
    "\n",
    "                        row = [log_time, mban, tdata_id,offerRecord_req['intent'],offerRecord_req['offerGroup'],offerRecord_req['inventorySpaceId'],sub_offer_string,int(offerRecord_req['Rank']) ,int(offerRecord_res['Rank']),len(sub_offer_list),int(offerRecord_res['Rank'])-int(offerRecord_req['Rank']),shuffle]\n",
    "                        df_length = len(df_stg)\n",
    "                        df_stg.loc[df_length] = row\n",
    "        else:\n",
    "            continue\n",
    "    return df_stg    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f178a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################################### READ CONTEXT ###################################################################\n",
    "myvars = Read_Contexts()\n",
    "EMAIL_TO = myvars['Email_To_US'].split(',' or ';')\n",
    "EMAIL_SUBJECT = 'ATT - Response/Request Code'\n",
    "EMAIL_FROM = myvars['Email_From']\n",
    "EMAIL_SMTP = myvars['Email_Host']\n",
    "EMAIL_PORT = myvars['Email_Port']\n",
    "special_password =  urllib.parse.quote(myvars['GP_Password'])\n",
    "print('contexts Loaded')\n",
    "\n",
    "###################################################### CREATE CONNECTION ################################################################\n",
    "conn = psycopg2.connect(host=myvars['GP_Server'], dbname=myvars['GP_DB'], user=myvars['GP_User'], password=myvars['GP_Password'], port=myvars['GP_Port'])\n",
    "conn2 = psycopg2.connect(host=myvars['GP_Server'], dbname=myvars['GP_DB'], user=myvars['GP_User'], password=myvars['GP_Password'], port=myvars['GP_Port'])\n",
    "conn_string = 'postgresql+psycopg2://'+myvars['GP_User']+':'+special_password+'@'+myvars['GP_Server']+':'+str(myvars['GP_Port'])+'/'+myvars['GP_DB']\n",
    "engine = create_engine(conn_string)\n",
    "print('Connections Created')\n",
    "\n",
    "####################################################### GET WSA DATA #####################################################################\n",
    "#param_st_dt = datetime.strptime('2022-10', '%d-%m-%Y').date()\n",
    "#param_st_dt = dt.date(2022, 10, 15)\n",
    "#param_ed_dt = dt.date(2022, 10, 16)\n",
    "\n",
    "param_st_dt =''\n",
    "param_ed_dt =''\n",
    "\n",
    "\n",
    "df_wsa,StartDate,TodayDate = Get_Dates_and_WSA_Data(conn, param_st_dt, param_ed_dt)\n",
    "conn.commit()\n",
    "print('DF_WSA LOADED')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85d6fb5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################### PARSE REQUEST/RESPONSE ###########################################################\n",
    "\n",
    "df_stg=pd.DataFrame(columns=['log_time','mban','tdata_id', 'intent','offer_group','offer_type','offer_group_members','original_rank','afiniti_rank', 'n_propositions','rank_change','shuffle'])\n",
    "df_stg = parse_request_response(df_wsa,df_stg)\n",
    "print('Response/Request Parsed')\n",
    "workingdir = \"/dbstorage/offload_de/\"\n",
    "csvfile = workingdir+\"processed_responses.csv\"\n",
    "f=open(csvfile,'wb') # opens file for writing (erases contents)\n",
    "df_stg.to_csv(csvfile, sep='~', encoding='utf-8', index=False)\n",
    "f.close()\n",
    "cursor = conn2.cursor()\n",
    "cursor.execute(f\"delete FROM decisioning_de.processed_responses_v2 WHERE log_time >= '{str(StartDate)}' and log_time < '{str(TodayDate)}'\")\n",
    "cursor.close()\n",
    "conn.commit() \n",
    "cursor = conn2.cursor()\n",
    "cursor.execute(\"\"\"INSERT INTO decisioning_de.processed_responses_v2 SELECT log_time::timestamp(3), mban, tdata_id, intent, offer_group, offer_type, offer_group_members, original_rank::int,\n",
    "afiniti_rank::int, n_propositions::int, rank_change::int, shuffle::int FROM decisioning_de.ext_processed_responses;\"\"\")\n",
    "cursor.close()\n",
    "conn2.commit()\n",
    "\n",
    "\n",
    "######################################################## DODGY RESPONSES ##################################################################\n",
    "\n",
    "Dodgy_Responses(df_wsa, engine,conn, StartDate, TodayDate)\n",
    "print('Dodgy responses Done')\n",
    "''''\n",
    "\n",
    "######################################################### Final Table Insertion ###########################################################\n",
    "\n",
    "    try:\n",
    "        print(\"inserting data\")\n",
    "        df_stg.to_sql('processed_responses_v2', con = engine, schema='decisioning_de', if_exists = 'append', chunksize = 1000, index = False)\n",
    "    except (Exception, psycopg2.DatabaseError) as error:\n",
    "            print(error)\n",
    "    conn.close()\n",
    "    conn2.close()\n",
    "else:\n",
    "    print(\"Data is Already Up to Date\")\n",
    "'''''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8 (default, Apr 13 2021, 15:08:03) [MSC v.1916 64 bit (AMD64)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "f529cd43cd1b6a734ae14126c00545461456752d68fb4d42a842c7a4d525c261"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
